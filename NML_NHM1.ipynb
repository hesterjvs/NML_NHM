{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFgvX4s5qMQEuwXjcGFqjm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hesterjvs/NML_NHM/blob/main/NML_NHM1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqJaORUFbyG1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Import data\n",
        "df = pd.read_excel('NML_Sample.xlsx', engine='openpyxl')\n",
        "\n",
        "# Display the first 10 rows of the DataFrame\n",
        "#print(df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "import pdb\n",
        "\n",
        "# Load CSV file from Publish or Perish:\n",
        "file_path = \"/content/PoPCites.csv\"  # Use actual file path\n",
        "df = pd.read_csv(file_path)\n",
        "#df.head(10) #test file was read\n",
        "\n",
        "# Ensure there is a column with DOIs\n",
        "if 'DOI' not in df.columns:\n",
        "    raise ValueError(\"The CSV file must include a 'DOI' column.\")\n",
        "#else:\n",
        "#   print(\"DOI exists.\") #Test if DOI column exists\n",
        "\n",
        "# Function to fetch abstract using CrossRef API\n",
        "def fetch_abstract(doi):\n",
        "    url = f\"https://api.crossref.org/works/{doi}\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            return data.get('message', {}).get('abstract', None)\n",
        "        else:\n",
        "            print(f\"Failed to fetch DOI: {doi}, Status code: {response.status_code}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching DOI: {doi}, Error: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Add abstracts to the dataframe\n",
        "df['Full_Abstract'] = df['DOI'].apply(fetch_abstract)\n",
        "\n",
        "# Save the updated CSV\n",
        "output_file = \"updated_publications.csv\"\n",
        "df.to_csv(output_file, index=False)\n",
        "print(f\"Abstracts saved to {output_file}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "_IJSJH1qR9Za"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Load the CSV file\n",
        "file_path = \"your_file.csv\"  # Replace with your file path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Define keywords for screening\n",
        "keywords = [\"generative AI\", \"accessibility\", \"museum collections\", \"alt-text\", \"cultural heritage\"]\n",
        "\n",
        "# Function to check if any keyword is in the abstract\n",
        "def is_relevant(abstract):\n",
        "    pattern = \"|\".join([re.escape(keyword) for keyword in keywords])\n",
        "    return bool(re.search(pattern, abstract, re.IGNORECASE))\n",
        "\n",
        "# Apply the function to the abstract column\n",
        "df['Relevant'] = df['Abstract'].apply(lambda x: is_relevant(str(x)))\n",
        "\n",
        "# Filter relevant abstracts\n",
        "relevant_abstracts = df[df['Relevant']]\n",
        "\n",
        "# Save results to a new CSV\n",
        "relevant_abstracts.to_csv(\"relevant_abstracts.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "tPXza_XnSx62"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}